## 义码当仙之并发编程

### 一、多线程基础
> 示例项目：concurrency01-thread-basis

#### 进程与线程  
每个正在系统上运行的程序都是一个进程。每个进程包含一到多个线程。线程是一组指令的集合，或者是程序的特殊段，它可以在程序里独立执行。也可以把它理解为代码运行的上下文。所以线程基本上是轻量级的进程，它负责在单个程序里执行多任务。通常由操作系统负责多个线程的调度和执行。  
使用线程可以把占据时间长的程序中的任务放到后台去处理，程序的运行速度可能加快，在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下可以释放一些珍贵的资源如内存占用等等。  
如果有大量的线程会影响性能，因为操作系统需要在它们之间切换，更多的线程需要更多的内存空间，线程的中止需要考虑其对程序运行的影响。通常块模型数据是在多个线程间共享的，需要防止线程死锁情况的发生。  
总结：<font color="#dd0000">进程是所有线程的集合，每一个线程是进程中的一条执行路径。</font>

#### 为什么要使用多线程？  
提高程序的效率。

#### 多线程的使用场景
- 数据库连接池
- 迅雷下载  
此时采用多线程，只能提高下载效率，并不能提高下载速度，下载速度由网络运营商提供的带宽决定。  
多线程下载，即同一时刻，有多个线程（多个执行路径）同时执行下载任务。
- 分发短信

#### 线程的分类
- 用户线程（非守护线程）与守护线程（如GC线程）
- 主线程（一个进程中一定会有主线程）、子线程

> Java中有两种线程，一种是用户线程，另一种是守护线程。  
用户线程是指用户自定义创建的线程，主线程停止，用户线程不会停止。    
守护线程：当进程不存在或主线程停止，守护线程也会被停止。  
使用setDaemon(true)方法将线程设置为守护线程。

示例代码：concurrency01-thread-basis.DaemonThreadDemo.java  

#### 多线程的创建方式
- 方式一：继承Thread类，重写run方法  
示例代码：concurrency01-thread-basis.ThreadDemo01.java

- 方式二：实现Runnable接口，重写run方法（推荐）  
原因实现了接口还可以继续继承，继承了类不能再继承。  
示例代码：concurrency01-thread-basis.ThreadDemo02.java

- 方式三：使用匿名内部类  
示例代码：concurrency01-thread-basis.ThreadDemo03.java  

- 方式四：使用线程池进行管理

#### 同步（Synchronous）与异步（Asynchronous）
同步和异步通常来形容一次方法调用，同步方法调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。  
异步方法调用更像一个消息传递，一旦开始，方法调用就会立即返回，调用者就可以继续后续的操作。 
异步方法通常会在另外一个线程中“真实”地执行。整个过程，不会阻碍调用者的工作。

![](images/同步与异步.png)

#### 并发（Concurrency）和并行（Parallelism）
并发和并行是两个非常容易被混淆的概念。他们都可以表示两个或者多个任务一起执行，但是侧重点有所不同。并发偏重于多个任务交替执行，而多个任务之间有可能还是串行的，而并行是真正意义上的“同时执行”。  

#### 临界区
临界区用来表示一种公共资源或者说共享数据，可以被多个线程使用，但是每一次只能有一个线程使用它，一旦临界区资源被占用，其他线程要想使用这个资源就必须等待。  

#### 阻塞（Blocking）和非阻塞（Non-Blocking）
阻塞和非阻塞通常用来形容很多线程间的相互影响。比如一个线程占用了临界区资源，那么其他所有需要这个资源的线程就必须在这个临界区中等待。等待会导致线程挂起，这种情况就是阻塞。此时，如果占用资源的线程一直不愿意释放资源，那么其他阻塞在这个临界区上的线程都不能工作。  
非阻塞的意思与之相反，它强调没有一个线程可以妨碍其他线程执行，所有的线程都会尝试不断向前执行。

#### 多线程的状态（生命周期）
线程从创建、运行到结束总是处于下面七个状态之一：新建状态、就绪状态、运行状态、阻塞状态、等待状态、超时等待状态、以及死亡状态。  

![](images/线程的7种状态.png)

![](images/线程的状态图.jpeg)

- 新建（初始）状态  
当用new操作符创建一个线程时，例如new Thread(r)，线程还没有开始运行，此时线程处在新建状态。当一个线程处于新建状态时，程序还没有开始运行线程中的代码。

- 就绪（可运行）状态  
一个新创建的线程并不自动开始运行，要执行线程，必须调用线程的start()方法。
当线程对象调用start()方法即启动了线程，start()方法创建线程运行的系统资源，并调度线程运行run()方法。
当start()方法返回后，线程就处于就绪状态。处于就绪状态的线程并不一定立即运行run()方法，线程还必须同其他线程竞争CPU时间。
只有获得CPU时间才可以运行线程。
因为在单CPU的计算机系统中，不可能同时运行多个线程，一个时刻仅有一个线程处于运行状态，因此此时可能有多个线程处于就绪状态。
对多个处于就绪状态的线程是由Java运行时系统的线程调度程序(thread scheduler)来调度的。

> 1. 就绪状态只是说明当前线程有资格运行，调度程序没有挑选到该线程，该线程就永远处于就绪状态。
> 2. 调用线程的start()方法，此线程进入就绪状态。
> 3. 当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些线程也将进入就绪状态。
> 4. 当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入就绪状态。
> 5. 锁池里的线程拿到对象锁后，进入就绪状态。

- 运行状态  
当线程获得CPU时间后，它才进入运行状态，真正开始执行run()方法。

- 阻塞状态  
线程运行过程中，可能由于各种原因进入阻塞状态:
> 1. 线程通过调用sleep方法进入睡眠状态；
> 2. 线程调用一个在I/O上被阻塞的操作，即该操作在输入输出操作完成之前不会返回到它的调用者；
> 3. 线程试图得到一个锁，而该锁正被其他线程持有；
> 4. 线程在等待某个触发条件；

- 等待    
处于这种状态的线程不会被分配CPU执行时间，它们要等待被显式地唤醒，否则会处于无限期等待的状态。

- 超时等待    
处于这种状态的线程不会被分配CPU执行时间，不过无须无限期等待被其他线程显示地唤醒，在达到一定时间后它们会自动唤醒。

- 死亡（终止）状态  
有两个原因会导致线程死亡：
> 1. run方法正常退出而自然死亡，
> 2. 一个未捕获的异常终止了run方法而使线程猝死。  

当线程的run()方法完成时，或者主线程的main()方法完成时，我们就认为它终止了。这个线程对象也许是活的，但是，它已经不是一个单独执行的线程。线程一旦终止了，就不能复生。  
在一个终止的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。  
为了确定线程在当前是否存活着（就是要么是可运行的，要么是被阻塞了），需要使用isAlive方法。如果是可运行或被阻塞，这个方法返回true； 如果线程仍旧是new状态且不是可运行的，或者线程死亡了，则返回false。

#### 常用线程API

|API|描述|
|:----|:----|
|start()|启动线程|
|currentThread()|获取当前线程对象|
|getID()|获取当前线程ID。Thread-编号，该编号从0开始|
|getName()|获取当前线程名称|
|sleep(long mill)|休眠线程|
|stop()|停止线程|
|Thread()|分配一个新的Thread对象|
|Thread(String name)|分配一个新的Thread对象，具有指定的name。|
|Thread(Runable r)|分配一个新的Thread对象|
|Thread(Runable r, String name)|分配一个新的Thread对象|
 
#### join()方法
当在主线程当中执行到t1.join()方法时，就认为主线程应该把执行权让给t1  
示例代码：concurrency01-thread-basis.ThreadJoinDemo.java  

#### 线程的优先级
现代操作系统基本采用时分的形式调度运行的线程，线程分配得到的时间片的多少决定了线程使用处理器资源的多少，也对应了线程优先级这个概念。  
在JAVA线程中，通过一个int priority来控制优先级，范围为1-10，其中10最高，默认值为5。下面是源码（基于1.8）中关于priority的一些量和方法。  
示例代码：concurrency01-thread-basis.ThreadPriorityDemo.java    

#### yield()方法
Thread.yield()方法的作用：暂停当前正在执行的线程，并执行其他线程。（可能没有效果）  
yield()让当前正在运行的线程回到可运行状态，以允许具有相同优先级的其他线程获得运行的机会。  
因此，使用yield()的目的是让具有相同优先级的线程之间能够适当的轮换执行。但是，实际中无法保证yield()达到让步的目的，因为，让步的线程可能被线程调度程序再次选中。  
结论：大多数情况下，yield()将导致线程从运行状态转到可运行状态，但有可能没有效果。  

<hr>

### 二、Java内存模型（JMM）
> 示例项目：concurrency02-jmm

#### 线程安全
> 引用《深入理解Java虚拟机》中的定义：
当多个线程访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替运行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确的结果，那这个对象是线程安全的。
  
当多个线程共享同一个全局变量，做写操作的时候，可能会受到其他线程的干扰，做读操作的时候不会发生线程安全问题。—— Java内存模型  

#### 线程安全解决办法
1. 问：如何解决多线程之间线程安全问题？  
答：使用多线程之间同步synchronized或使用锁（lock）。

2. 问：为什么使用线程同步或使用锁能解决线程安全问题呢？  
答：将可能会发生数据冲突问题（线程不安全问题）的临界区，只能让当前一个线程进行执行。代码执行完成后释放锁，然后才能让其他线程进行执行。这样就可以解决线程不安全问题。

3. 问：什么是多线程同步？  
答：当多个线程共享同一个资源，不会受到其他线程的干扰。

> 线程安全示例（多窗口抢票）代码：concurrency02-jmm.GrabTicketDemo  

#### 内置锁（synchronized）
Java提供了一种内置的锁机制来支持原子性。
每一个Java对象都可以用作一个实现同步的锁，称为内置锁，线程进入同步代码块之前自动获取到锁，代码块执行完成正常退出或代码块中抛出异常退出时会释放掉锁。  
内置锁为互斥锁，即线程A获取到锁后，线程B阻塞直到线程A释放锁，线程B才能获取到同一个锁。  
内置锁使用synchronized关键字实现，synchronized关键字有两种用法：  
1. 修饰需要进行同步的方法（所有访问状态变量的方法都必须进行同步），此时充当锁的对象为调用同步方法的对象； 
2. 同步代码块和直接使用synchronized修饰需要同步的方法是一样的，但是锁的粒度可以更细，并且充当锁的对象不一定是this，也可以是其它对象，所以使用起来更加灵活。 

- 同步代码块synchronized  
```text
将可能会发生线程安全问题的代码，包括起来
synchronized(同一个数据){
   可能会发生线程冲突问题
}

同步代码块 
synchronized(对象)//这个对象可以为任意对象 
{ 
   需要被同步的代码 
}
```
示例代码：  
```java
private void sale() {
    // 同步代码块，锁可以是this或者任意全局对象
    synchronized (this){
        if(count > 0){
            System.out.println(Thread.currentThread().getName() + ", 正在出售第" + (100 - count + 1) + "张票...");
            count --;
        }
    }
}
```

> 对象如同锁，持有锁的线程可以在同步中执行。没持有锁的线程即使获取CPU的执行权，也进不去。  
> 同步的前提： 
> 1. 必须要有两个或者两个以上的线程   
> 2. 必须是多个线程使用同一个锁
>   
> 必须保证同步中只能有一个线程在运行。  
> 1. 好处：解决了多线程的安全问题  
> 2. 弊端：多个线程需要判断锁、抢锁，较为消耗资源

- 同步（非静态）方法：在方法上修饰synchronized称为同步方法。  
 
示例代码： 
```java
private synchronized void sale() {
    // 注意这里必须再判断一次。当余票只剩最后一张，假设窗口1先获取到锁，执行下面的购买，将买到第100张票，此时余票为0。
    // 与此同时，窗口1释放锁，并由窗口2获取到锁继续购票，则将买到第101张票。即发生了超票购买的线程安全问题。。。
    if(count > 0){
        System.out.println(Thread.currentThread().getName() + ", 正在出售第" + (100 - count + 1) + "张票...");
        count --;
    }
}
```
问：非静态同步方法使用的是什么锁？  
答：非静态同步方法使用this锁。  
证明方式: 一个线程使用同步代码块(this锁)，另一个线程使用同步函数。如果两个线程抢票不能实现同步，那么会出现数据错误。  
> 证明示例代码: concurrency02-jmm.Test01.java 

- 静态同步方法  

问：什么是静态同步方法？  
答：方法上加上static关键字，使用 synchronized 关键字修饰或者使用 类.class 文件。  
静态的同步方法使用的锁是该方法所属字节码文件对象。  
可以用getClass方法获取，也可以用当前类名.class表示。 

示例代码：  
```java
private static void sale() {
    // 同步代码块，锁可以是this 或者任意对象
    synchronized (TicketSalesThread.class){
        if(count > 0){
            System.out.println(Thread.currentThread().getName() + ", 正在出售第" + (100 - count + 1) + "张票...");
            count --;
        }
    }
}
```
> 总结：
> 1. synchronized 修饰非静态方法使用的锁是当前对象的this锁。  
> 2. synchronized 修饰静态方法使用的锁是当前类的字节码文件。  

#### 死锁（Deadlock）、饥饿（Starvation）和活锁（Livelock）
死锁、饥饿和活锁都属于多线程的活跃性问题。如果发现上述几种情况，那么相关线程就不再活跃，也就是说它可能很难再继续往下执行了。

死锁应该是最糟糕的一种情况了（当然，其他几种情况也好不到哪里去），如下图显示了一个死锁的发生：  
![IMAGE](images/死锁示例图.png)

A、B、C、D四辆小车都在这种情况下都无法继续行驶了。他们彼此之间相互占用了其他车辆的车道，如果大家都不愿意释放自己的车道，那么这个状况将永远持续下去，谁都不可能通过，死锁是一个很严重的并且应该避免和实时小心的问题。

饥饿是指某一个或者多个线程因为种种原因无法获得所要的资源，导致一直无法执行。比如它的优先级可能太低，而高优先级的线程不断抢占它需要的资源，导致低优先级线程无法工作。在自然界中，母鸡给雏鸟喂食很容易出现这种情况：由于雏鸟很多，食物有限，雏鸟之间的食物竞争可能非常厉害，经常抢不到食物的雏鸟有可能被饿死。线程的饥饿非常类似这种情况。此外，某一个线程一直占着关键资源不放，导致其他需要这个资源的线程无法正常执行，这种情况也是饥饿的一种。于死锁想必，饥饿还是有可能在未来一段时间内解决的（比如，高优先级的线程已经完成任务，不再疯狂执行）。

活锁是一种非常有趣的情况。不知道大家是否遇到过这么一种场景，当你要做电梯下楼时，电梯到了，门开了，这是你正准备出去。但很不巧的是，门外一个人当着你的去路，他想进来。于是，你很礼貌地靠左走，礼让对方。同时，对方也非常礼貌的靠右走，希望礼让你。结果，你们俩就又撞上了。于是乎，你们都意识到了问题，希望尽快避让对方，你立即向右边走，同时，他立即向左边走。结果，又撞上了！不过介于人类的智慧，我相信这个动作重复两三次后，你应该可以顺利解决这个问题。因为这个时候，大家都会本能地对视，进行交流，保证这种情况不再发生。但如果这种情况发生在两个线程之间可能就不那么幸运了。如果线程智力不够。且都秉承着“谦让”的原则，主动将资源释放给他人使用，那么久会导致资源不断地在两个线程间跳动，而没有一个线程可以同时拿到所有资源正常执行。这种情况就是活锁。

#### 死锁产生原因：同步中嵌套同步  

> 示例代码: concurrency02-jmm.DeadLockDemo

查看死锁日志信息：  
```text
jps
jstack ${pid} >> DeadLockDemo.txt
```

#### ThreadLocal  
ThreadLocal提供一个线程局部变量，访问某个线程拥有自己局部变量。  
当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。

ThreadLocal的接口方法：
- void set(Object value)  
设置当前线程的线程局部变量的值。  
- public Object get()  
该方法返回当前线程所对应的线程局部变量。  
- public void remove()  
将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。  
需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。   
- protected Object initialValue()  
返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。  
这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。  
ThreadLocal中的缺省实现直接返回一个null。 

> 示例代码：concurrency02-jmm.ThreadLocalDemo

ThreadLocal实现原理：ThreadLocal通过map集合，map.put("当前线程", 值);


### 多线程三大特性：原子性、可见性、有序性
- 什么是原子性

> 即一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。
一个很经典的例子就是银行账户转账问题：   
比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。这2个操作必须要具备原子性才能保证不出现一些意外的问题。  
我们操作数据也是如此，比如i = i+1；其中就包括：读取i的值，计算i，写入i。  
这行代码在Java中是不具备原子性的，则多线程运行肯定会出问题，所以也需要我们使用同步和lock这些东西来确保这个特性了。   
原子性其实就是保证数据一致、线程安全一部分  

- 什么是可见性

> 当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。  
若两个线程在不同的cpu，那么线程1改变了i的值还没刷新到主存，线程2又使用了i，那么这个i值肯定还是之前的，线程1对变量的修改线程没看到，这就是可见性问题。  

- 什么是有序性

> 程序执行的顺序按照代码的先后顺序执行。  
一般来说处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。如下：  
```java
int a = 10;   //语句1  
int r = 2;    //语句2  
a = a + 3;    //语句3  
r = a*a;      //语句4  
```
因为指令的重排序，执行顺序可能为 2-1-3-4，1-3-2-4，但绝不可能为 2-1-4-3，因为这打破了依赖关系。  
显然重排序对单线程运行是不会有任何问题，而多线程就不一定了，所以我们在多线程编程时就得考虑这个问题。 

### Java内存模型

> 共享内存模型指的就是Java内存模型(简称JMM)。JMM决定一个线程对共享变量写入时，能对另一个线程可见。  
从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，  
每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。  
本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。  

![](images/Java内存模型图.png)

> 从上图来看，线程A与线程B之间如要通信的话，必须要经历下面2个步骤：  
> 1. 首先，线程A把本地内存A中更新过的共享变量刷新到主内存中去。  
> 2. 然后，线程B到主内存中去读取线程A之前已更新过的共享变量。

下面通过示意图来说明这两个步骤： 

![](images/JMM-线程间通信示意图.png) 

> 如上图所示，本地内存A和B有主内存中共享变量x的副本。假设初始时，这三个内存中的x值都为0。    
线程A在执行时，把更新后的x值（假设值为1）临时存放在自己的本地内存A中。  
当线程A和线程B需要通信时，线程A首先会把自己本地内存中修改后的x值刷新到主内存中，此时主内存中的x值变为了1。  
随后，线程B到主内存中去读取线程A更新后的x值，此时线程B的本地内存的x值也变为了1。  
从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。  
JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证。  

> 总结：什么是Java内存模型？  
java内存模型简称jmm，定义了一个线程对另一个线程可见。  
共享变量存放在主内存中，每个线程都有自己的本地内存，当多个线程同时访问一个数据的时候，可能本地内存没有及时刷新到主内存，所以就会发生线程安全问题。  

### volatile

> 可见性也就是说一旦某个线程修改了该被volatile修饰的变量，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，可以立即获取修改之后的值。  
在Java中为了加快程序的运行效率，对一些变量的操作通常是在该线程的寄存器或是CPU缓存上进行的，之后才会同步到主存中，而加了volatile修饰符的变量则是直接读写主存。  
volatile 保证了线程间共享变量的及时可见性，但不能保证原子性。

> 示例代码：concurrency02-jmm.VolatileDemo.java

已经将结果设置为fasle，为什么还一直在运行呢？  
原因：线程之间是不可见的，读取的是副本，没有及时读取到主内存结果。  
解决办法使用Volatile关键字将解决线程之间可见性, 强制线程每次读取该值的时候都去“主内存”中取值。

#### volatile特性
1. 保证变量对所有的线程的可见性，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。  
但普通变量做不到这点，普通变量的值在线程间传递均需要通过主内存来完成。
2. 禁止指令重排序优化。有volatile修饰的变量，赋值后多执行了一个“load addl $0x0, (%esp)”操作，  
这个操作相当于一个内存屏障（指令重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；  
（什么是指令重排序：是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理）

volatile 性能：volatile 的读性能消耗与普通变量几乎相同，但是写操作稍慢，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。  

#### volatile与synchronized区别
1. synchronized保证操作的原子性和内存可见性；  
2. volatile只能保证内存可见性；  
3. volatile不需要加锁，比synchronized更轻量级，并不会阻塞线程（volatile不会造成线程的阻塞；synchronized可能会造成线程的阻塞）；  
4. volatile标记的变量不会被编译器优化，而synchronized标记的变量可以被编译器优化（比如编译器重排序的优化）；  
5. volatile是变量修饰符，仅能用于变量，而synchronized是一个方法和块的修饰符。  
volatile本质是在告诉JVM当前变量在寄存器中的值是不确定的，使用前需要先从主存中读取，因此可以实现可见行。而对于n=n+1,n++等操作，volatile关键字将失效，不能起到像synchronized一样的线程同步（原子性）的效果。

### 重排序
是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理。  
通俗的描述： CPU会对代码的执行进行优化，但不会对有依赖关系的代码做重排序，代码的执行顺序可能会发生变化，但是执行的结果不会发生改变。

#### 数据依赖性
如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型：

|名称|代码示例|说明|
|:----|:----|:----|
|写后读|a = 1;b = a;|写一个变量之后，再读这个位置|
|写后写|a = 1;a = 2;|写一个变量之后，再写这个变量|
|读后写|a = b;b = 1;|读一个变量之后，再写这个变量|

上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。  
编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。  
注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。  

#### as-if-serial语义  

as-if-serial语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。  
编译器，runtime 和处理器都必须遵守as-if-serial语义。  
为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。  
但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。  
为了具体说明，请看下面计算圆面积的代码示例：
```java
double pi  = 3.14;        //A
double r   = 1.0;         //B
double area = pi * r * r; //C
```
上面三个操作的数据依赖关系如下图所示：  

![](images/JMM-计算圆面积-示例图1.png)

如上图所示，A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。  
因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。  
但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。下图是该程序的两种执行顺序：  

![](images/JMM-计算圆面积-示例图2.png)  

as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器，runtime 和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。  
as-if-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。  

#### 程序顺序规则

根据happens- before的程序顺序规则，上面计算圆的面积的示例代码存在三个happens-before关系：  
```text
1. A happens-before B；
2. B happens-before C；
3. A happens-before C；
```
这里的第3个happens- before关系，是根据happens-before的传递性推导出来的。  
这里A happens-before B，但实际执行时B却可以排在A之前执行（看上面的重排序后的执行顺序）。  
如果A happens-before B，JMM并不要求A一定要在B之前执行。  
JMM仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。  
这里操作A的执行结果不需要对操作B可见；而且重排序操作A和操作B后的执行结果，与操作A和操作B按happens-before顺序执行的结果一致。  
在这种情况下，JMM会认为这种重排序并不非法（not illegal），JMM允许这种重排序。  
在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度。  
编译器和处理器遵从这一目标，从happens-before的定义我们可以看出，JMM同样遵从这一目标。  

#### 重排序对多线程的影响  
```java
class ReorderExample {
    int a = 0;
    boolean flag = false;

    public void writer() {
        a = 1;                     //1
        flag = true;               //2
    }

    public void reader() {
        if (flag) {                //3
            int i =  a * a;        //4
            ……
        }
    }
}
```
flag变量是个标记，用来标识变量a是否已被写入。这里假设有两个线程A和B，A首先执行writer()方法，随后B线程接着执行reader()方法。线程B在执行操作4时，能否看到线程A在操作1对共享变量a的写入？  
答案是：不一定能看到。  

由于操作1和操作2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。  
让我们先来看看，当操作1和操作2重排序时，可能会产生什么效果？请看下面的程序执行时序图：  

![](images/JMM-重排序对程序影响-示例图1.png)  

如上图所示，操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。  
由于条件判断为真，线程B将读取变量a。此时，变量a还根本没有被线程A写入，在这里多线程程序的语义被重排序破坏了！  

注：用红色的虚箭线表示错误的读操作，用绿色的虚箭线表示正确的读操作。  

下面再让我们看看，当操作3和操作4重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。下面是操作3和操作4重排序后，程序的执行时序图：  

![](images/JMM-重排序对程序影响-示例图2.png)  

在程序中，操作3和操作4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。  
为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。  
以处理器的猜测执行为例，执行线程B的处理器可以提前读取并计算a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。  
当接下来操作3的条件判断为真时，就把该计算结果写入变量i中。

从图中我们可以看出，猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！

在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；  
但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。  

<hr>

## 三、多线程之间通讯  
> 示例项目：concurrency03-thread-communication

### 什么是多线程之间通讯？  
多线程之间通讯，其实就是多个线程在操作同一个资源，但是操作的动作不同。  

### 生产者与消费者  
> 示例代码：concurrency03-thread-communication.ProducterCustomerDemo.java

### wait、notify方法  
1. 因为涉及到对象锁，wait、notify必须都放在synchronized中来使用，持有同一把锁；   
2. wait必须暂定当前正在执行的线程，并释放资源锁，让其他线程可以有机会运行；  
3. notify/notifyall：唤醒因锁池中的线程，使之运行。  
注意：一定要在线程同步中使用，并且是同一个锁的资源！  

### wait与sleep区别  
1. 对于sleep()方法，首先要知道该方法是属于Thread类中的，而wait()方法则是属于Object类中的。  
2. sleep()方法导致程序暂停执行指定的时间，让出cpu时间片给其他线程，但是他的监控状态依然保持者，当指定的时间到了又会自动恢复运行状态。在调用sleep()方法的过程中，线程不会释放对象锁。  
3. 当调用wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。  

### lock锁
在 jdk1.5 之后，并发包中新增了 Lock 接口和相关实现类，用来实现锁功能，Lock 接口提供了与 synchronized 关键字类似的同步功能，但需要在使用时手动获取锁和释放锁。  

> 示例代码：concurrency03-thread-communication.ProducterCustomerDemo2.java

#### lock用法  
```java
Lock lock = new ReentrantLock();
lock.lock();
try{
    // 可能会出现线程安全的操作
}finally{
    // 一定在finally中释放锁
    // 也不能把获取锁在try中进行，因为有可能在获取锁的时候抛出异常
    lock.unlock();
}
```

#### Lock与synchronized关键字的区别  
Lock接口可以尝试非阻塞地获取锁。当前线程尝试获取锁，如果这一时刻锁没有被其他线程获取到，则成功获取并持有锁。  
Lock接口能被中断地获取锁。 与 synchronized 不同，获取到锁的线程能够响应中断，当获取到的锁的线程被中断时，中断异常将会被抛出，同时锁会被释放。  
Lock接口在指定的截止时间之前获取锁，如果截止时间到了依旧无法获取锁，则返回。  

#### condition用法
condition的功能类似于在传统的线程技术中，Object.wait()和Object.notify()的功能。  

```java
Lock lock = new ReentrantLock();
Condition condition = lock.newCondition();
res.condition.await();  // 类似wait
res.condition.signal(); // 类似notify
```

<hr>

## 线程池原理分析  
> 示例项目：concurrency04-thread-pool  

### 并发包

#### CountDownLatch（计数器）
CountDownLatch 类位于java.util.concurrent包下，利用它可以实现类似计数器的功能。  
比如有一个任务A，它要等待其他2个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。  
CountDownLatch是通过一个计数器来实现的，计数器的初始值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就会减1。  
当计数器值到达0时，它表示所有的线程已经完成了任务，然后在闭锁上等待的线程就可以恢复执行任务。  

> 示例代码：concurrency04-thread-pool.CountDownLatchDemo.java

#### CyclicBarrier（屏障）

CyclicBarrier初始化时规定一个数目，然后计算调用了CyclicBarrier.await()进入等待的线程数。当线程数达到了这个数目时，所有进入等待状态的线程被唤醒并继续。  
CyclicBarrier就象它名字的意思一样，可看成是个障碍， 所有的线程必须到齐后才能一起通过这个障碍。   
CyclicBarrier初始时还可带一个Runnable的参数， 此Runnable任务在CyclicBarrier的数目达到后，所有其它线程被唤醒前被执行。  

> 示例代码：concurrency04-thread-pool.CyclicBarrierDemo.java

#### Semaphore（计数信号量）
Semaphore是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信号，申请到后用完归还，超过阈值后，线程申请许可信号将会被阻塞。  
Semaphore可以用来构建一些对象池，资源池之类的，比如数据库连接池，我们也可以创建计数为1的Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。它的用法如下：  
```java
semaphore.availablePermits(); // 获取当前可用的资源数量    
semaphore.acquire();          // 申请资源    
semaphore.release();          // 释放资源   
```

> 示例代码：concurrency04-thread-pool.SemaphoreDemo.java    
 
### 并发队列

在并发队列上JDK提供了两套实现：  
1. 以ConcurrentLinkedQueue为代表的高性能非阻塞队列，  
2. 以BlockingQueue接口为代表的阻塞队列。  
无论哪种都实现了Queue接口。  

### 阻塞队列与非阻塞队  
阻塞队列与普通队列的区别在于，当队列是空的时，从队列中获取元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。  
试图从空的阻塞队列中获取元素的线程将会被阻塞，直到其他的线程往空的队列插入新的元素。同样，试图往已满的阻塞队列中添加新元素的线程同样也会被阻塞，  
直到其他的线程使队列重新变得空闲起来，如从队列中移除一个或者多个元素，或者完全清空队列。  

1. ArrayDeque：数组双端队列   
2. PriorityQueue：优先级队列   
3. ConcurrentLinkedQueue：基于链表的并发队列   
4. DelayQueue：延期阻塞队列（阻塞队列实现了BlockingQueue接口）   
5. ArrayBlockingQueue：基于数组的并发阻塞队列   
6. LinkedBlockingQueue：基于链表的FIFO阻塞队列  
7. LinkedBlockingDeque：基于链表的FIFO双端阻塞队列  
8. PriorityBlockingQueue：带优先级的无界阻塞队列  
9. SynchronousQueue：并发同步阻塞队列  

#### ConcurrentLinkedQueue  
是一个适用于高并发场景下的队列，通过无锁的方式，实现了高并发状态下的高性能。  
通常ConcurrentLinkedQueue性能好于BlockingQueue。它是一个基于链接节点的无界线程安全队列。  
该队列的元素遵循先进先出的原则。头是最先加入的，尾是最近加入的，该队列不允许null元素。  
ConcurrentLinkedQueue重要方法:  
```text
add()和offer()：都是加入元素的方法（在ConcurrentLinkedQueue中这两个方法没有任何区别）  
poll()和peek()：都是取头元素节点，区别在于前者会删除元素，后者不会。  
```
> 示例代码：concurrency04-thread-pool.ConcurrentLinkedQueueDemo

#### BlockingQueue
阻塞队列（BlockingQueue）是一个支持两个附加操作的队列，这两个附加的操作是：  
1. 在队列为空时，获取元素的线程会等待队列变为非空。  
2. 当队列满时，存储元素的线程会等待队列可用。  

阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿取元素的线程。  
阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿取元素。  

BlockingQueue即阻塞队列，从阻塞这个词可以看出，在某些情况下对阻塞队列的访问可能会造成阻塞。被阻塞的情况主要有如下两种：  
1. 当队列满了的时候进行入队列操作  
2. 当队列空了的时候进行出队列操作  

因此，当一个线程试图对一个已经满了的队列进行入队列操作时，它将会被阻塞，除非有另一个线程做了出队列操作；   
同样，当一个线程试图对一个空队列进行出队列操作时，它将会被阻塞，除非有另一个线程进行了入队列操作。  

在Java中，BlockingQueue的接口位于java.util.concurrent包中（在Java5版本开始提供），由上面介绍的阻塞队列的特性可知，阻塞队列是线程安全的。  

在新增的concurrent包中，BlockingQueue很好的解决了多线程中，如何高效安全“传输”数据的问题。  
通过这些高效并且线程安全的队列类，为我们快速搭建高质量的多线程程序带来极大的便利。

常用的队列主要有以下两种：（当然通过不同的实现方式，还可以延伸出很多不同类型的队列，DelayQueue就是其中的一种）
先进先出（FIFO）：先插入的队列的元素也最先出队列，类似于排队的功能。从某种程度上来说这种队列也体现了一种公平性。  
后进先出（LIFO）：后插入队列的元素最先出队列，这种队列优先处理最近发生的事件。  

多线程环境中，通过队列可以很容易实现数据共享，比如经典的“生产者”和“消费者”模型中，通过队列可以很便利地实现两者之间的数据共享。  
假设我们有若干生产者线程，另外又有若干个消费者线程。如果生产者线程需要把准备好的数据共享给消费者线程，利用队列的方式来传递数据，就可以很方便地解决他们之间的数据共享问题。  
但如果生产者和消费者在某个时间段内，万一发生数据处理速度不匹配的情况呢？  
理想情况下，如果生产者产出数据的速度大于消费者消费的速度，并且当生产出来的数据累积到一定程度的时候，那么生产者必须暂停等待一下（阻塞生产者线程），以便等待消费者线程把累积的数据处理完毕，反之亦然。  
然而，在concurrent包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。  
好在此时，强大的concurrent包横空出世了，而他也给我们带来了强大的BlockingQueue。  
（在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤醒）  

#### ArrayBlockingQueue  
ArrayBlockingQueue是一个有边界的阻塞队列，它的内部实现是一个数组。有边界的意思是它的容量是有限的，我们必须在其初始化的时候指定它的容量大小，容量大小一旦指定就不可改变。    
ArrayBlockingQueue是以先进先出的方式存储数据，最新插入的对象是尾部，最新移出的对象是头部。  

> 示例代码：concurrency04-thread-pool.ArrayBlockingQueueDemo.java

#### LinkedBlockingQueue  
LinkedBlockingQueue阻塞队列容量大小的配置是可选的，如果我们初始化时指定一个大小，它就是有边界的，如果不指定，它就是无边界的。  
说是无边界，其实是采用了默认大小为Integer.MAX_VALUE的容量 。它的内部实现是一个链表。  
和ArrayBlockingQueue一样，LinkedBlockingQueue也是以先进先出的方式存储数据，最新插入的对象是尾部，最新移出的对象是头部。  

> 示例代码：concurrency04-thread-pool.LinkedBlockingQueueDemo.java

#### PriorityBlockingQueue
PriorityBlockingQueue是一个没有边界的队列，它的排序规则和java.util.PriorityQueue一样。  
需要注意是，PriorityBlockingQueue中允许插入null对象的。  
所有插入PriorityBlockingQueue的对象必须实现java.lang.Comparable接口，队列优先级的排序规则就是按照我们对这个接口的实现来定义的。    
另外，我们可以从PriorityBlockingQueue获得一个迭代器Iterator，但这个迭代器并不保证按照优先级顺序进行迭代。  

#### SynchronousQueue
SynchronousQueue队列内部仅允许容纳一个元素。当一个线程插入一个元素后会被阻塞，除非这个元素被另一个线程消费。  


### 线程池

#### 什么是线程池  
Java中的线程池是运用场景最多的并发框架，几乎所有需要异步或并发执行任务的程序都可以使用线程池。  
在开发过程中，合理地使用线程池能够带来3个好处：  
1. 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。  
2. 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。  
3. 提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控，但是要做到合理利用。  

#### 线程池作用
线程池是为突然大量爆发的线程设计的，通过有限的几个固定线程为大量的操作服务，减少了创建和销毁线程所需的时间，从而提高效率。  
如果一个线程的时间非常长，就没必要用线程池了（不是不能做长时间操作，而是不宜），况且我们还不能控制线程池中线程的开始、挂起和中止。  

#### ThreadPoolExecutor
Java是天生就支持并发的语言，支持并发意味着多线程，线程的频繁创建在高并发及大数据量是非常消耗资源的，因此java提供了线程池。    
在JDK1.5以前的版本中，线程池的使用是及其简陋的，但是在JDK1.5后，有了很大的改善。    
JDK1.5之后加入了java.util.concurrent包，java.util.concurrent包的加入给予开发人员开发并发程序以及解决并发问题很大的帮助。    
并发包下的Executor接口虽然作为一个非常旧的接口（JDK1.5 2004年发布），但是很多程序员对于其中的一些原理还是不熟悉。  
Executor框架的最顶层实现是ThreadPoolExecutor类，  
Executors工厂类中提供的newScheduledThreadPool、newFixedThreadPool、newCachedThreadPool方法其实也只是ThreadPoolExecutor的构造函数参数不同而已。  
通过传入不同的参数，就可以构造出适用于不同应用场景下的线程池。

```text
// 构造方法
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue<Runnable> workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
                          
// 参数
corePoolSize - 即使空闲时仍保留在池中的线程数，除非设置allowCoreThreadTimeOut
maximumPoolSize - 池中允许的最大线程数
keepAliveTime - 当线程数大于内核时，这是多余的空闲线程在终止前等待新任务的最大时间。
unit - keepAliveTime参数的时间单位，有7种静态属性。
workQueue - 用于在执行任务之前使用的队列。这个队列将仅保存execute方法提交的Runnable任务。
threadFactory - 执行程序创建新线程时使用的工厂
handler - 执行被阻止时使用的处理程序，因为达到线程限制和队列容量
// 异常
IllegalArgumentException - 如果以下某项成立： 
corePoolSize < 0 
keepAliveTime < 0 
maximumPoolSize <= 0 
maximumPoolSize < corePoolSize
NullPointerException - 如果 workQueue 或threadFactory 或handler 为空
```
RejectedExecutionHandler提供了四个预定义的处理程序策略：  
1. 在默认ThreadPoolExecutor.AbortPolicy ，处理程序会引发运行RejectedExecutionException后排斥反应。  
2. 在ThreadPoolExecutor.CallerRunsPolicy中，调用execute本身的线程运行任务。 这提供了一个简单的反馈控制机制，将降低新任务提交的速度。  
3. 在ThreadPoolExecutor.DiscardPolicy中 ，简单地删除无法执行的任务。  
4. 在ThreadPoolExecutor.DiscardOldestPolicy中 ，如果执行程序没有关闭，则工作队列头部的任务被删除，然后重试执行（可能会再次失败，导致重复）。 


#### 线程池四种创建方式  
Java通过Executors（jdk1.5并发包）提供四种线程池，分别为：  
- newCachedThreadPool：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。  
```java
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue<Runnable>());
}
```
>可缓存线程池，说道缓存一般离不开过期时间，该线程池也是，corePoolSize设置为0，maximumPoolSize设置为int最大值，  
不同的是，线程池传入的队列是SynchronousQueue，一个同步队列，该队列没有任何容量，每次插入新数据，必须等待消费完成。  
当有新任务到达时，线程池没有线程则创建线程处理，处理完成后该线程缓存60秒，过期后回收，线程过期前有新任务到达时，则使用缓存的线程来处理。 

- newFixedThreadPool：创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。  
```java
public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue<Runnable>());
}
```
> 顾名思义，就是创建线程数量固定的线程池，线程池的corePoolSize和maximumPoolSize大小一样，并且keepAliveTime为0，  
传入的队列LinkedBlockingQueue为无界队列。传入一个无界队列，maximumPoolSize参数是不起作用的。  

- newScheduledThreadPool：创建一个定长线程池，支持定时及周期性任务执行。  
```java
public static ScheduledExecutorService newScheduledThreadPool(
            int corePoolSize, ThreadFactory threadFactory) {
    return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);
}
``` 
> 这个线程池使用了ScheduledThreadPoolExecutor，该线程池继承自ThreadPoolExecutor, 执行任务的时候可以指定延迟多少时间执行，或者周期性执行。  
 
- newSingleThreadExecutor：创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。   
```java
public static ExecutorService newSingleThreadExecutor() {
    return new FinalizableDelegatedExecutorService
        (new ThreadPoolExecutor(1, 1,
                                0L, TimeUnit.MILLISECONDS,
                                new LinkedBlockingQueue<Runnable>()));
}
``` 
> 从代码中也能看得出来，corePoolSize和maximumPoolSize都是1，keepAliveTime是0L, 传入的队列是无界队列。线程池中永远只有一个线程在工作。  






  




 





















  



  













































 





















 



	














 



















